"""
AI_Solarbot - Gemini/ChatGPT í†µí•© AI í•¸ë“¤ëŸ¬
Gemini ìš°ì„  ì‚¬ìš©, ë¬´ë£Œ í•œë„ ì´ˆê³¼ì‹œ ChatGPTë¡œ ìë™ ì „í™˜
"""

import os
import openai
import google.generativeai as genai
from dotenv import load_dotenv
import asyncio
import sys
from typing import Optional, Dict, Any
import time
import random
import json
from datetime import datetime
import io
from google_drive_handler import drive_handler

load_dotenv()

# API í‚¤ ì„¤ì •
openai.api_key = os.getenv('OPENAI_API_KEY')
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')
genai.configure(api_key=GEMINI_API_KEY)

class AIHandler:
    def __init__(self):
        self.gemini_models = {
            'gemini-1.5-flash': genai.GenerativeModel('gemini-1.5-flash'),
            'gemini-2.0-flash-exp': genai.GenerativeModel('gemini-2.0-flash-exp'),
            'gemini-2.5-flash': genai.GenerativeModel('gemini-2.5-flash')
        }
        self.default_model = 'gemini-2.0-flash-exp'
        self.user_preferences = {}  # ì‚¬ìš©ìë³„ ëª¨ë¸ ì„ íƒ ì €ì¥
        
        # êµ¬ê¸€ ë“œë¼ì´ë¸Œ ê¸°ë°˜ ì„¤ì •
        self.ai_handler_folder_name = "íŒœì†”ë¼_AIê´€ë¦¬_ì‹œìŠ¤í…œ"
        self.usage_file_name = "usage_tracker.json"
        self.usage_data = None
        
    def ensure_ai_handler_folder(self) -> str:
        """AI í•¸ë“¤ëŸ¬ í´ë” í™•ì¸/ìƒì„±"""
        try:
            if not drive_handler.authenticate():
                raise Exception("êµ¬ê¸€ ë“œë¼ì´ë¸Œ ì¸ì¦ ì‹¤íŒ¨")
            
            # ê¸°ì¡´ í´ë” ê²€ìƒ‰
            query = f"name='{self.ai_handler_folder_name}' and mimeType='application/vnd.google-apps.folder'"
            results = drive_handler.service.files().list(q=query, fields='files(id, name)').execute()
            folders = results.get('files', [])
            
            if folders:
                return folders[0]['id']
            
            # í´ë” ìƒì„±
            folder_metadata = {
                'name': self.ai_handler_folder_name,
                'mimeType': 'application/vnd.google-apps.folder'
            }
            folder = drive_handler.service.files().create(body=folder_metadata, fields='id').execute()
            return folder.get('id')
            
        except Exception as e:
            raise Exception(f"AI í•¸ë“¤ëŸ¬ í´ë” ìƒì„± ì‹¤íŒ¨: {str(e)}")
        
    def load_usage_data(self) -> dict:
        """êµ¬ê¸€ ë“œë¼ì´ë¸Œì—ì„œ ì‚¬ìš©ëŸ‰ ë°ì´í„° ë¡œë“œ"""
        if self.usage_data is not None:
            return self.usage_data
            
        try:
            folder_id = self.ensure_ai_handler_folder()
            
            # ë°ì´í„° íŒŒì¼ ê²€ìƒ‰
            query = f"name='{self.usage_file_name}' and parents in '{folder_id}'"
            results = drive_handler.service.files().list(q=query, fields='files(id, name)').execute()
            files = results.get('files', [])
            
            if files:
                # ê¸°ì¡´ íŒŒì¼ ì½ê¸°
                file_id = files[0]['id']
                content = drive_handler.service.files().get_media(fileId=file_id).execute()
                self.usage_data = json.loads(content.decode('utf-8'))
                return self.usage_data
            else:
                # ì´ˆê¸° ë°ì´í„° ìƒì„±
                self.usage_data = {
                    "daily_gemini_calls": 0,
                    "daily_chatgpt_calls": 0,
                    "last_reset_date": datetime.now().strftime("%Y-%m-%d"),
                    "total_gemini_calls": 0,
                    "total_chatgpt_calls": 0
                }
                self.save_usage_data()
                return self.usage_data
                
        except Exception as e:
            print(f"ì‚¬ìš©ëŸ‰ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.usage_data = {
                "daily_gemini_calls": 0,
                "daily_chatgpt_calls": 0,
                "last_reset_date": datetime.now().strftime("%Y-%m-%d"),
                "total_gemini_calls": 0,
                "total_chatgpt_calls": 0
            }
            return self.usage_data
    
    def save_usage_data(self):
        """êµ¬ê¸€ ë“œë¼ì´ë¸Œì— ì‚¬ìš©ëŸ‰ ë°ì´í„° ì €ì¥"""
        if self.usage_data is None:
            return
            
        try:
            folder_id = self.ensure_ai_handler_folder()
            content = json.dumps(self.usage_data, ensure_ascii=False, indent=2)
            
            # ê¸°ì¡´ íŒŒì¼ ê²€ìƒ‰
            query = f"name='{self.usage_file_name}' and parents in '{folder_id}'"
            results = drive_handler.service.files().list(q=query, fields='files(id, name)').execute()
            files = results.get('files', [])
            
            if files:
                # ê¸°ì¡´ íŒŒì¼ ì—…ë°ì´íŠ¸
                file_id = files[0]['id']
                media_body = drive_handler.MediaIoBaseUpload(
                    io.BytesIO(content.encode('utf-8')),
                    mimetype='application/json'
                )
                drive_handler.service.files().update(
                    fileId=file_id,
                    media_body=media_body
                ).execute()
            else:
                # ìƒˆ íŒŒì¼ ìƒì„±
                file_metadata = {
                    'name': self.usage_file_name,
                    'parents': [folder_id]
                }
                media_body = drive_handler.MediaIoBaseUpload(
                    io.BytesIO(content.encode('utf-8')),
                    mimetype='application/json'
                )
                drive_handler.service.files().create(
                    body=file_metadata,
                    media_body=media_body,
                    fields='id'
                ).execute()
                
        except Exception as e:
            print(f"ì‚¬ìš©ëŸ‰ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def reset_daily_usage_if_needed(self):
        """ë‚ ì§œê°€ ë°”ë€Œë©´ ì¼ì¼ ì‚¬ìš©ëŸ‰ ë¦¬ì…‹"""
        usage_data = self.load_usage_data()
        today = datetime.now().strftime("%Y-%m-%d")
        if usage_data["last_reset_date"] != today:
            usage_data["daily_gemini_calls"] = 0
            usage_data["daily_chatgpt_calls"] = 0
            usage_data["last_reset_date"] = today
            self.usage_data = usage_data
            self.save_usage_data()
    
    async def chat_with_ai(self, message: str, user_name: str = "ì‚¬ìš©ì", user_id: str = None) -> tuple:
        """AIì™€ ëŒ€í™” (Gemini ìš°ì„ , ì‹¤íŒ¨ì‹œ ChatGPT)"""
        self.reset_daily_usage_if_needed()
        
        system_prompt = f"""ë‹¹ì‹ ì€ AI_Solarbotì…ë‹ˆë‹¤. 
ChatGPT ì‹¤ë¬´ ê°•ì˜ì™€ íŒœì†”ë¼(íƒœì–‘ê´‘) ì—…ë¬´ë¥¼ ë„ì™€ì£¼ëŠ” ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

ì‚¬ìš©ì ì •ë³´: {user_name}ë‹˜

ì‘ë‹µ ê°€ì´ë“œë¼ì¸:
1. ì¹œê·¼í•˜ê³  ì „ë¬¸ì ì¸ í†¤ìœ¼ë¡œ ë‹µë³€
2. íƒœì–‘ê´‘ ê´€ë ¨ ì§ˆë¬¸ì—ëŠ” êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì •ë³´ ì œê³µ
3. ChatGPT ì‹¤ë¬´ í™œìš©ì— ëŒ€í•´ì„œëŠ” ì‹¤ì „ ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ ì¡°ì–¸
4. í•„ìš”ì‹œ ê´€ë ¨ ëª…ë ¹ì–´(/prompt, /solar ë“±) ì•ˆë‚´
5. ë‹µë³€ì€ ê°„ê²°í•˜ë˜ ì¶©ë¶„í•œ ì •ë³´ í¬í•¨
6. ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•˜ì—¬ ì¹œê·¼í•œ ë¶„ìœ„ê¸° ì¡°ì„±
"""
        
        # ì‚¬ìš©ìê°€ ì„ íƒí•œ ëª¨ë¸ í™•ì¸
        selected_model = self.get_user_model(user_id) if user_id else self.default_model
        
        # GPT-4oë¥¼ ì„ íƒí•œ ê²½ìš° ë°”ë¡œ ChatGPT ì‚¬ìš©
        if selected_model == 'gpt-4o':
            try:
                response = openai.chat.completions.create(
                    model="gpt-4o",
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": message}
                    ],
                    max_tokens=1000,
                    temperature=0.7
                )
                
                usage_data = self.load_usage_data()
                usage_data["daily_chatgpt_calls"] += 1
                usage_data["total_chatgpt_calls"] += 1
                self.usage_data = usage_data
                self.save_usage_data()
                
                return response.choices[0].message.content.strip(), "ğŸ§  padiem"
                
            except Exception as e:
                print(f"GPT-4o API ì˜¤ë¥˜: {str(e)}")
                # GPT-4o ì‹¤íŒ¨ì‹œ Geminië¡œ ì „í™˜
        
        # Gemini ëª¨ë¸ ì‚¬ìš© (2.0 ë˜ëŠ” 2.5)
        usage_data = self.load_usage_data()
        if usage_data["daily_gemini_calls"] < 1400:  # ì¼ì¼ í•œë„: 1500íšŒ
            try:
                # ì„ íƒëœ Gemini ëª¨ë¸ ì‚¬ìš©
                if selected_model == 'gemini-2.5-flash':
                    model = self.gemini_models['gemini-2.5-flash']
                    model_name = "ğŸ§  padiem"
                else:  # ê¸°ë³¸ê°’: gemini-2.0-flash-exp
                    model = self.gemini_models['gemini-2.0-flash-exp']
                    model_name = "ğŸ§  padiem"
                
                response = model.generate_content(f"{system_prompt}\n\nì‚¬ìš©ì ì§ˆë¬¸: {message}")
                usage_data["daily_gemini_calls"] += 1
                usage_data["total_gemini_calls"] += 1
                self.usage_data = usage_data
                self.save_usage_data()
                
                return response.text.strip(), model_name
                
            except Exception as e:
                print(f"Gemini API ì˜¤ë¥˜: {str(e)}")
                # Gemini ì‹¤íŒ¨ì‹œ ChatGPTë¡œ ì „í™˜
        
        # 2ì°¨: ChatGPT ë°±ì—… ì‹œë„
        try:
            response = openai.chat.completions.create(
                model="gpt-4o",  # ìµœì‹  ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ ì‚¬ìš©
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": message}
                ],
                max_tokens=1000,
                temperature=0.7
            )
            
            self.usage_data["daily_chatgpt_calls"] += 1
            self.usage_data["total_chatgpt_calls"] += 1
            self.save_usage_data()
            
            return response.choices[0].message.content.strip(), "ğŸ§  padiem"
            
        except Exception as e:
            return f"""ì£„ì†¡í•©ë‹ˆë‹¤. AI ì„œë¹„ìŠ¤ì— ì¼ì‹œì ì¸ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.

ì˜¤ë¥˜ ë‚´ìš©: {str(e)}

ğŸ”„ ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.
ë˜ëŠ” ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ì‚¬ìš©í•´ë³´ì„¸ìš”:
â€¢ /help - ë„ì›€ë§
â€¢ /status - ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸""", "âŒ ì˜¤ë¥˜"

    async def calculate_solar_power(self, capacity_kw: float, location: str = "ì„œìš¸", angle: int = 30) -> tuple:
        """íƒœì–‘ê´‘ ë°œì „ëŸ‰ ê³„ì‚°"""
        prompt = f"""
íƒœì–‘ê´‘ ë°œì „ ì „ë¬¸ê°€ë¡œì„œ ë‹¤ìŒ ì¡°ê±´ì˜ íƒœì–‘ê´‘ ì‹œìŠ¤í…œì„ ìƒì„¸íˆ ë¶„ì„í•´ì£¼ì„¸ìš”:

ğŸ”§ ì„¤ì¹˜ ì¡°ê±´:
- ì„¤ì¹˜ ìš©ëŸ‰: {capacity_kw}kW
- ì„¤ì¹˜ ì§€ì—­: {location}
- ì„¤ì¹˜ ê°ë„: {angle}ë„
- ë°©í–¥: ë‚¨í–¥ (ìµœì )

ğŸ“Š ë¶„ì„ ìš”ì²­ ì‚¬í•­:
1. ì—°ê°„ ì˜ˆìƒ ë°œì „ëŸ‰ (kWh)
2. ì›”ë³„ ë°œì „ëŸ‰ ë¶„í¬ (ê³„ì ˆë³„ íŠ¹ì„± í¬í•¨)
3. ê²½ì œì„± ë¶„ì„ (ì´ˆê¸° íˆ¬ìë¹„, ì—°ê°„ ìˆ˜ìµ, íšŒìˆ˜ ê¸°ê°„)
4. íš¨ìœ¨ ìµœì í™” ë°©ì•ˆ 3ê°€ì§€
5. ì§€ì—­ë³„ íŠ¹ì„± ê³ ë ¤ì‚¬í•­

ì‹¤ë¬´ì— ë°”ë¡œ í™œìš©í•  ìˆ˜ ìˆë„ë¡ êµ¬ì²´ì ì¸ ìˆ«ìì™€ ì‹¤ìš©ì ì¸ ì¡°ì–¸ì„ í¬í•¨í•´ì£¼ì„¸ìš”.
"""
        
        try:
            usage_data = self.load_usage_data()
            if usage_data["daily_gemini_calls"] < 1400:
                response = self.gemini_models['gemini-2.0-flash-exp'].generate_content(prompt)
                usage_data["daily_gemini_calls"] += 1
                usage_data["total_gemini_calls"] += 1
                self.usage_data = usage_data
                self.save_usage_data()
                
                return f"ğŸŒ íƒœì–‘ê´‘ ë°œì „ëŸ‰ ë¶„ì„ ê²°ê³¼\n\n{response.text.strip()}", "ğŸ§  padiem"
            else:
                # ChatGPT ë°±ì—…
                response = openai.chat.completions.create(
                    model="gpt-4o",
                    messages=[
                        {"role": "system", "content": "ë‹¹ì‹ ì€ íƒœì–‘ê´‘ ë°œì „ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=1200,
                    temperature=0.3
                )
                
                usage_data["daily_chatgpt_calls"] += 1
                usage_data["total_chatgpt_calls"] += 1
                self.usage_data = usage_data
                self.save_usage_data()
                
                return f"ğŸŒ íƒœì–‘ê´‘ ë°œì „ëŸ‰ ë¶„ì„ ê²°ê³¼\n\n{response.choices[0].message.content.strip()}", "ğŸ§  padiem"
                
        except Exception as e:
            return f"""íƒœì–‘ê´‘ ê³„ì‚° ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}

ğŸ“Š ê¸°ë³¸ ê³„ì‚° (ê·¼ì‚¬ì¹˜):
â€¢ {capacity_kw}kW ì‹œìŠ¤í…œ
â€¢ {location} ê¸°ì¤€ ì˜ˆìƒ ë°œì „ëŸ‰
â€¢ ì—°ê°„: {capacity_kw * 1300:,.0f}kWh
â€¢ ì›”í‰ê· : {capacity_kw * 1300/12:,.0f}kWh
â€¢ ì˜ˆìƒ ì—°ê°„ ìˆ˜ìµ: {capacity_kw * 1300 * 150:,.0f}ì›

ë” ì •í™•í•œ ê³„ì‚°ì€ ì‹œìŠ¤í…œ ë³µêµ¬ í›„ ê°€ëŠ¥í•©ë‹ˆë‹¤.""", "âŒ ì˜¤ë¥˜"

    async def generate_prompt_template(self, topic: str) -> tuple:
        """ì£¼ì œë³„ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±"""
        prompt = f"""
"{topic}" ê´€ë ¨ ì—…ë¬´ì— ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” íš¨ê³¼ì ì¸ ChatGPT í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ 3ê°œ ë§Œë“¤ì–´ì£¼ì„¸ìš”.

ê° í…œí”Œë¦¿ì€ ë‹¤ìŒ êµ¬ì¡°ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”:
1. ğŸ¯ ì—­í•  ì„¤ì • - "ë‹¹ì‹ ì€ ~ì „ë¬¸ê°€ì…ë‹ˆë‹¤"
2. ğŸ“ êµ¬ì²´ì  ì§€ì‹œì‚¬í•­ - "ë‹¤ìŒ ì‘ì—…ì„ í•´ì£¼ì„¸ìš”"
3. ğŸ“‹ ì¶œë ¥ í˜•ì‹ ì§€ì • - "ê²°ê³¼ë¥¼ ~í˜•íƒœë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”"
4. âš™ï¸ ì¶”ê°€ ì¡°ê±´ (í•„ìš”ì‹œ)

ì‹¤ë¬´ì—ì„œ ë°”ë¡œ ë³µì‚¬í•´ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ì™„ì„±ëœ í˜•íƒœë¡œ ì œê³µí•´ì£¼ì„¸ìš”.
ê° í…œí”Œë¦¿ì—ëŠ” ì‚¬ìš© ì˜ˆì‹œë„ í¬í•¨í•´ì£¼ì„¸ìš”.
"""
        
        try:
            usage_data = self.load_usage_data()
            if usage_data["daily_gemini_calls"] < 1400:
                response = self.gemini_models['gemini-2.0-flash-exp'].generate_content(prompt)
                usage_data["daily_gemini_calls"] += 1
                usage_data["total_gemini_calls"] += 1
                self.usage_data = usage_data
                self.save_usage_data()
                
                return f"ğŸ“ '{topic}' í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n\n{response.text.strip()}", "ğŸ§  padiem"
            else:
                # ChatGPT ë°±ì—…
                response = openai.chat.completions.create(
                    model="gpt-4o",
                    messages=[
                        {"role": "system", "content": "ë‹¹ì‹ ì€ ChatGPT í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=1200,
                    temperature=0.5
                )
                
                usage_data["daily_chatgpt_calls"] += 1
                usage_data["total_chatgpt_calls"] += 1
                self.usage_data = usage_data
                self.save_usage_data()
                
                return f"ğŸ“ '{topic}' í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n\n{response.choices[0].message.content.strip()}", "ğŸ§  padiem"
                
        except Exception as e:
            return f"""í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}

ğŸ“‹ ê¸°ë³¸ '{topic}' í…œí”Œë¦¿:
ë‹¹ì‹ ì€ {topic} ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ë‹¤ìŒ ì‘ì—…ì„ ë„ì™€ì£¼ì„¸ìš”: [êµ¬ì²´ì  ìš”ì²­]
ê²°ê³¼ë¥¼ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”:
1. í•µì‹¬ ìš”ì•½
2. ìƒì„¸ ë‚´ìš©  
3. ì‹¤í–‰ ë°©ì•ˆ

/template ëª…ë ¹ì–´ë¡œ ë” ë§ì€ í…œí”Œë¦¿ì„ í™•ì¸í•˜ì„¸ìš”.""", "âŒ ì˜¤ë¥˜"
    
    async def explain_homework(self, homework_content: str, user_name: str = "ì‚¬ìš©ì") -> tuple:
        """ê³¼ì œ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ìì„¸í•œ ì„¤ëª… ìƒì„±"""
        self.reset_daily_usage_if_needed()
        
        system_prompt = f"""ë‹¹ì‹ ì€ íŒœì†”ë¼ ChatGPT ì‹¤ë¬´ êµìœ¡ ì „ë¬¸ ê°•ì‚¬ì…ë‹ˆë‹¤.
ì£¼ì–´ì§„ ê³¼ì œ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ í•™ìƒë“¤ì´ ì´í•´í•˜ê¸° ì‰½ë„ë¡ ìì„¸í•œ ì„¤ëª…ì„ ì œê³µí•´ì£¼ì„¸ìš”.

ì‚¬ìš©ì ì •ë³´: {user_name}ë‹˜

ì„¤ëª… ê°€ì´ë“œë¼ì¸:
1. ê³¼ì œì˜ ëª©ì ê³¼ í•™ìŠµ ëª©í‘œ ëª…í™•íˆ ì„¤ëª…
2. ë‹¨ê³„ë³„ í’€ì´ ë°©ë²• ì œì‹œ
3. ì‹¤ë¬´ í™œìš© ì˜ˆì‹œ í¬í•¨
4. ì£¼ì˜ì‚¬í•­ê³¼ íŒ ì œê³µ
5. ì˜ˆìƒ ì†Œìš”ì‹œê°„ê³¼ ë‚œì´ë„ ì•ˆë‚´
6. ì¹œê·¼í•˜ê³  ê²©ë ¤ì ì¸ í†¤ ìœ ì§€

ì¶œë ¥ í˜•ì‹:
ğŸ“š ê³¼ì œ ê°œìš”
ğŸ¯ í•™ìŠµ ëª©í‘œ  
ğŸ“‹ ë‹¨ê³„ë³„ ê°€ì´ë“œ
ğŸ’¡ ì‹¤ë¬´ í™œìš© íŒ
âš ï¸ ì£¼ì˜ì‚¬í•­
â±ï¸ ì˜ˆìƒ ì†Œìš”ì‹œê°„
ğŸŒŸ ì„±ê³µ í¬ì¸íŠ¸
"""
        
        # 1ì°¨: Gemini ì‹œë„
        usage_data = self.load_usage_data()
        if usage_data["daily_gemini_calls"] < 1400:
            try:
                prompt = f"{system_prompt}\n\në¶„ì„í•  ê³¼ì œ ë‚´ìš©:\n{homework_content}"
                response = self.gemini_models['gemini-2.0-flash-exp'].generate_content(prompt)
                usage_data["daily_gemini_calls"] += 1
                usage_data["total_gemini_calls"] += 1
                self.usage_data = usage_data
                self.save_usage_data()
                
                return response.text.strip(), "ğŸ§  padiem"
                
            except Exception as e:
                print(f"Gemini API ì˜¤ë¥˜: {str(e)}")
        
        # 2ì°¨: ChatGPT ë°±ì—…
        try:
            response = openai.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": f"ë‹¤ìŒ ê³¼ì œë¥¼ ìì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”:\n\n{homework_content}"}
                ],
                max_tokens=1500,
                temperature=0.7
            )
            
            usage_data = self.load_usage_data()
            usage_data["daily_chatgpt_calls"] += 1
            usage_data["total_chatgpt_calls"] += 1
            self.usage_data = usage_data
            self.save_usage_data()
            
            return response.choices[0].message.content.strip(), "ğŸ§  padiem"
            
        except Exception as e:
            return f"""ê³¼ì œ ì„¤ëª… ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}

ğŸ“š ê¸°ë³¸ ê³¼ì œ ê°€ì´ë“œ:
1. ê³¼ì œ ë‚´ìš©ì„ ì²œì²œíˆ ì½ì–´ë³´ì„¸ìš”
2. ìš”êµ¬ì‚¬í•­ì„ ì •í™•íˆ íŒŒì•…í•˜ì„¸ìš”  
3. ë‹¨ê³„ë³„ë¡œ ì°¨ê·¼ì°¨ê·¼ ì§„í–‰í•˜ì„¸ìš”
4. ì‹¤ë¬´ ìƒí™©ì„ ìƒìƒí•˜ë©° ì‘ì„±í•˜ì„¸ìš”
5. ì™„ë£Œ í›„ ê²€í† í•´ë³´ì„¸ìš”

ğŸ’¡ ë„ì›€ì´ í•„ìš”í•˜ë©´ /help ëª…ë ¹ì–´ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.""", "âŒ ì˜¤ë¥˜"

    def get_usage_stats(self) -> dict:
        """ì‚¬ìš©ëŸ‰ í†µê³„ ë°˜í™˜"""
        self.reset_daily_usage_if_needed()
        usage_data = self.load_usage_data()
        return {
            "daily_gemini": usage_data["daily_gemini_calls"],
            "daily_chatgpt": usage_data["daily_chatgpt_calls"],
            "total_gemini": usage_data["total_gemini_calls"],
            "total_chatgpt": usage_data["total_chatgpt_calls"],
            "gemini_remaining": max(0, 1400 - usage_data["daily_gemini_calls"]),
            "date": usage_data["last_reset_date"]
        }
    
    def set_user_model(self, user_id, model_name):
        """ì‚¬ìš©ìë³„ AI ëª¨ë¸ ì„¤ì •"""
        available_models = ['gemini-2.0-flash-exp', 'gemini-2.5-flash', 'gpt-4o']
        if model_name in available_models:
            self.user_preferences[str(user_id)] = model_name
            return True
        return False
    
    def get_user_model(self, user_id):
        """ì‚¬ìš©ìì˜ ì„ íƒëœ AI ëª¨ë¸ ë°˜í™˜"""
        return self.user_preferences.get(str(user_id), self.default_model)
    
    def get_available_models(self):
        """ì‚¬ìš© ê°€ëŠ¥í•œ AI ëª¨ë¸ ëª©ë¡ ë°˜í™˜"""
        return {
            'gemini-2.0-flash-exp': 'ğŸ§  padiem (ë¹ ë¥´ê³  ê· í˜•ì¡íŒ ì„±ëŠ¥)',
            'gemini-2.5-flash': 'ğŸ§  padiem (ìµœê³  ì •í™•ë„, ìƒê° ëª¨ë“œ)',
            'gpt-4o': 'ğŸ§  padiem (OpenAI ìµœì‹  ëª¨ë¸)'
        }

def test_api_connection() -> dict:
    """API ì—°ê²° ìƒíƒœ í…ŒìŠ¤íŠ¸"""
    results = {
        "gemini": False,
        "openai": False,
        "error_messages": []
    }
    
    # Gemini í…ŒìŠ¤íŠ¸
    try:
        model = genai.GenerativeModel('gemini-2.5-flash')
        response = model.generate_content("Hello")
        results["gemini"] = True
    except Exception as e:
        results["error_messages"].append(f"Gemini ì˜¤ë¥˜: {str(e)}")
    
    # OpenAI í…ŒìŠ¤íŠ¸
    try:
        response = openai.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": "Hello"}],
            max_tokens=10
        )
        results["openai"] = True
    except Exception as e:
        results["error_messages"].append(f"OpenAI ì˜¤ë¥˜: {str(e)}")
    
    return results

# ì „ì—­ AI í•¸ë“¤ëŸ¬ ì¸ìŠ¤í„´ìŠ¤
ai_handler = AIHandler()
