"""
ìµœì‹  ê¸°ìˆ  ì •ë³´ ìë™ ì—…ë°ì´íŠ¸ ì‹œìŠ¤í…œ
GitHub API, NPM API, PyPI APIë¥¼ ì—°ë™í•˜ì—¬ ìµœì‹  ê¸°ìˆ  ì •ë³´ë¥¼ ìë™ìœ¼ë¡œ ì—…ë°ì´íŠ¸
"""

import os
import json
import asyncio
import aiohttp
import feedparser
import requests
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, asdict
from cachetools import TTLCache
from loguru import logger
import xmltodict

@dataclass
class TechNews:
    """ê¸°ìˆ  ë‰´ìŠ¤ ë°ì´í„° í´ë˜ìŠ¤"""
    title: str
    url: str
    description: str
    published: str
    source: str
    tags: List[str]
    score: float = 0.0

@dataclass
class PackageInfo:
    """íŒ¨í‚¤ì§€ ì •ë³´ ë°ì´í„° í´ë˜ìŠ¤"""
    name: str
    version: str
    description: str
    homepage: str
    repository: str
    downloads: int
    last_updated: str
    ecosystem: str  # npm, pypi, github

class TechInfoUpdater:
    """ìµœì‹  ê¸°ìˆ  ì •ë³´ ìë™ ì—…ë°ì´íŠ¸ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.github_token = os.getenv('GITHUB_TOKEN')
        self.stack_exchange_key = os.getenv('STACK_EXCHANGE_KEY')
        
        # ìºì‹œ ì„¤ì • (1ì‹œê°„ TTL)
        self.cache = TTLCache(maxsize=1000, ttl=3600)
        
        # RSS í”¼ë“œ URLë“¤
        self.rss_feeds = {
            'dev.to': 'https://dev.to/feed',
            'medium_tech': 'https://medium.com/feed/topic/technology',
            'hackernews': 'https://hnrss.org/frontpage',
            'github_blog': 'https://github.blog/feed/',
            'stackoverflow_blog': 'https://stackoverflow.blog/feed/',
            'python_org': 'https://www.python.org/jobs/feed/rss/',
            'nodejs_blog': 'https://nodejs.org/en/feed/blog.xml'
        }
        
        # API ì—”ë“œí¬ì¸íŠ¸
        self.api_endpoints = {
            'github_trending': 'https://api.github.com/search/repositories',
            'npm_registry': 'https://registry.npmjs.org',
            'pypi_api': 'https://pypi.org/pypi',
            'stack_exchange': 'https://api.stackexchange.com/2.3'
        }
        
        logger.info("TechInfoUpdater ì´ˆê¸°í™” ì™„ë£Œ")

    async def get_github_trending(self, language: str = '', time_range: str = 'daily') -> List[Dict]:
        """GitHub íŠ¸ë Œë”© ë¦¬í¬ì§€í† ë¦¬ ì •ë³´ ìˆ˜ì§‘"""
        try:
            cache_key = f"github_trending_{language}_{time_range}"
            if cache_key in self.cache:
                return self.cache[cache_key]
            
            # ë‚ ì§œ ê³„ì‚°
            if time_range == 'daily':
                since_date = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')
            elif time_range == 'weekly':
                since_date = (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d')
            else:
                since_date = (datetime.now() - timedelta(days=30)).strftime('%Y-%m-%d')
            
            # ê²€ìƒ‰ ì¿¼ë¦¬ êµ¬ì„±
            query = f"created:>{since_date}"
            if language:
                query += f" language:{language}"
            
            headers = {}
            if self.github_token:
                headers['Authorization'] = f'token {self.github_token}'
            
            params = {
                'q': query,
                'sort': 'stars',
                'order': 'desc',
                'per_page': 30
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.get(
                    self.api_endpoints['github_trending'],
                    headers=headers,
                    params=params
                ) as response:
                    if response.status == 200:
                        data = await response.json()
                        repositories = []
                        
                        for repo in data.get('items', []):
                            repo_info = {
                                'name': repo['full_name'],
                                'description': repo.get('description', ''),
                                'url': repo['html_url'],
                                'stars': repo['stargazers_count'],
                                'forks': repo['forks_count'],
                                'language': repo.get('language', ''),
                                'created_at': repo['created_at'],
                                'updated_at': repo['updated_at'],
                                'topics': repo.get('topics', [])
                            }
                            repositories.append(repo_info)
                        
                        self.cache[cache_key] = repositories
                        logger.info(f"GitHub íŠ¸ë Œë”© {len(repositories)}ê°œ ë¦¬í¬ì§€í† ë¦¬ ìˆ˜ì§‘ ì™„ë£Œ")
                        return repositories
                    else:
                        logger.error(f"GitHub API ì˜¤ë¥˜: {response.status}")
                        return []
                        
        except Exception as e:
            logger.error(f"GitHub íŠ¸ë Œë”© ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            return []

    async def get_npm_package_info(self, package_name: str) -> Optional[PackageInfo]:
        """NPM íŒ¨í‚¤ì§€ ì •ë³´ ìˆ˜ì§‘"""
        try:
            cache_key = f"npm_{package_name}"
            if cache_key in self.cache:
                return self.cache[cache_key]
            
            async with aiohttp.ClientSession() as session:
                # NPM ë ˆì§€ìŠ¤íŠ¸ë¦¬ì—ì„œ íŒ¨í‚¤ì§€ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                async with session.get(f"{self.api_endpoints['npm_registry']}/{package_name}") as response:
                    if response.status == 200:
                        data = await response.json()
                        latest_version = data['dist-tags']['latest']
                        latest_info = data['versions'][latest_version]
                        
                        # ë‹¤ìš´ë¡œë“œ í†µê³„ ê°€ì ¸ì˜¤ê¸°
                        downloads = 0
                        try:
                            async with session.get(f"https://api.npmjs.org/downloads/point/last-month/{package_name}") as dl_response:
                                if dl_response.status == 200:
                                    dl_data = await dl_response.json()
                                    downloads = dl_data.get('downloads', 0)
                        except:
                            pass
                        
                        package_info = PackageInfo(
                            name=package_name,
                            version=latest_version,
                            description=latest_info.get('description', ''),
                            homepage=latest_info.get('homepage', ''),
                            repository=latest_info.get('repository', {}).get('url', ''),
                            downloads=downloads,
                            last_updated=data['time'][latest_version],
                            ecosystem='npm'
                        )
                        
                        self.cache[cache_key] = package_info
                        return package_info
                    else:
                        logger.error(f"NPM API ì˜¤ë¥˜: {response.status}")
                        return None
                        
        except Exception as e:
            logger.error(f"NPM íŒ¨í‚¤ì§€ ì •ë³´ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            return None

    async def get_pypi_package_info(self, package_name: str) -> Optional[PackageInfo]:
        """PyPI íŒ¨í‚¤ì§€ ì •ë³´ ìˆ˜ì§‘"""
        try:
            cache_key = f"pypi_{package_name}"
            if cache_key in self.cache:
                return self.cache[cache_key]
            
            async with aiohttp.ClientSession() as session:
                async with session.get(f"{self.api_endpoints['pypi_api']}/{package_name}/json") as response:
                    if response.status == 200:
                        data = await response.json()
                        info = data['info']
                        
                        package_info = PackageInfo(
                            name=package_name,
                            version=info['version'],
                            description=info.get('summary', ''),
                            homepage=info.get('home_page', ''),
                            repository=info.get('project_urls', {}).get('Repository', ''),
                            downloads=0,  # PyPIëŠ” ë³„ë„ API í•„ìš”
                            last_updated=data['releases'][info['version']][0]['upload_time'] if data['releases'][info['version']] else '',
                            ecosystem='pypi'
                        )
                        
                        self.cache[cache_key] = package_info
                        return package_info
                    else:
                        logger.error(f"PyPI API ì˜¤ë¥˜: {response.status}")
                        return None
                        
        except Exception as e:
            logger.error(f"PyPI íŒ¨í‚¤ì§€ ì •ë³´ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            return None

    def parse_rss_feeds(self) -> List[TechNews]:
        """RSS í”¼ë“œì—ì„œ ê¸°ìˆ  ë‰´ìŠ¤ ìˆ˜ì§‘"""
        try:
            cache_key = "rss_feeds"
            if cache_key in self.cache:
                return self.cache[cache_key]
            
            all_news = []
            
            for source, url in self.rss_feeds.items():
                try:
                    feed = feedparser.parse(url)
                    
                    for entry in feed.entries[:10]:  # ìµœì‹  10ê°œë§Œ
                        # íƒœê·¸ ì¶”ì¶œ
                        tags = []
                        if hasattr(entry, 'tags'):
                            tags = [tag.term for tag in entry.tags]
                        
                        # ì ìˆ˜ ê³„ì‚° (ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜)
                        score = self._calculate_relevance_score(entry.title + ' ' + entry.get('summary', ''))
                        
                        news = TechNews(
                            title=entry.title,
                            url=entry.link,
                            description=entry.get('summary', '')[:200],
                            published=entry.get('published', ''),
                            source=source,
                            tags=tags,
                            score=score
                        )
                        all_news.append(news)
                        
                except Exception as e:
                    logger.error(f"RSS í”¼ë“œ íŒŒì‹± ì˜¤ë¥˜ ({source}): {e}")
                    continue
            
            # ì ìˆ˜ìˆœìœ¼ë¡œ ì •ë ¬
            all_news.sort(key=lambda x: x.score, reverse=True)
            
            self.cache[cache_key] = all_news[:50]  # ìƒìœ„ 50ê°œë§Œ ìºì‹œ
            logger.info(f"RSS í”¼ë“œì—ì„œ {len(all_news)} ê°œ ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ")
            return all_news[:50]
            
        except Exception as e:
            logger.error(f"RSS í”¼ë“œ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            return []

    async def get_stackoverflow_questions(self, tags: List[str], sort: str = 'activity') -> List[Dict]:
        """Stack Overflow ìµœì‹  ì§ˆë¬¸ ìˆ˜ì§‘"""
        try:
            cache_key = f"stackoverflow_{'-'.join(tags)}_{sort}"
            if cache_key in self.cache:
                return self.cache[cache_key]
            
            params = {
                'order': 'desc',
                'sort': sort,
                'tagged': ';'.join(tags),
                'site': 'stackoverflow',
                'pagesize': 20
            }
            
            if self.stack_exchange_key:
                params['key'] = self.stack_exchange_key
            
            async with aiohttp.ClientSession() as session:
                async with session.get(
                    f"{self.api_endpoints['stack_exchange']}/questions",
                    params=params
                ) as response:
                    if response.status == 200:
                        data = await response.json()
                        questions = []
                        
                        for question in data.get('items', []):
                            question_info = {
                                'title': question['title'],
                                'url': question['link'],
                                'score': question['score'],
                                'view_count': question['view_count'],
                                'answer_count': question['answer_count'],
                                'tags': question['tags'],
                                'creation_date': datetime.fromtimestamp(question['creation_date']).isoformat(),
                                'is_answered': question.get('is_answered', False)
                            }
                            questions.append(question_info)
                        
                        self.cache[cache_key] = questions
                        logger.info(f"Stack Overflow {len(questions)}ê°œ ì§ˆë¬¸ ìˆ˜ì§‘ ì™„ë£Œ")
                        return questions
                    else:
                        logger.error(f"Stack Exchange API ì˜¤ë¥˜: {response.status}")
                        return []
                        
        except Exception as e:
            logger.error(f"Stack Overflow ì§ˆë¬¸ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            return []

    def _calculate_relevance_score(self, text: str) -> float:
        """í…ìŠ¤íŠ¸ì˜ ê¸°ìˆ  ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°"""
        tech_keywords = [
            'python', 'javascript', 'react', 'node', 'ai', 'machine learning',
            'deep learning', 'api', 'database', 'cloud', 'docker', 'kubernetes',
            'programming', 'development', 'software', 'web', 'mobile', 'data',
            'algorithm', 'framework', 'library', 'github', 'open source'
        ]
        
        text_lower = text.lower()
        score = 0.0
        
        for keyword in tech_keywords:
            if keyword in text_lower:
                score += 1.0
        
        return score

    async def get_tech_summary(self, category: str = 'all') -> Dict[str, Any]:
        """ê¸°ìˆ  ì •ë³´ ì¢…í•© ìš”ì•½"""
        try:
            summary = {
                'timestamp': datetime.now().isoformat(),
                'category': category,
                'github_trending': [],
                'tech_news': [],
                'stackoverflow_questions': [],
                'popular_packages': {
                    'npm': [],
                    'pypi': []
                }
            }
            
            # ë³‘ë ¬ë¡œ ë°ì´í„° ìˆ˜ì§‘
            tasks = []
            
            if category in ['all', 'github']:
                tasks.append(self.get_github_trending('python'))
                tasks.append(self.get_github_trending('javascript'))
            
            if category in ['all', 'news']:
                tasks.append(asyncio.create_task(asyncio.to_thread(self.parse_rss_feeds)))
            
            if category in ['all', 'stackoverflow']:
                tasks.append(self.get_stackoverflow_questions(['python', 'javascript']))
            
            # ì¸ê¸° íŒ¨í‚¤ì§€ ì •ë³´
            popular_npm = ['react', 'vue', 'express', 'lodash', 'axios']
            popular_pypi = ['requests', 'numpy', 'pandas', 'django', 'flask']
            
            if category in ['all', 'packages']:
                for pkg in popular_npm[:3]:  # ìƒìœ„ 3ê°œë§Œ
                    tasks.append(self.get_npm_package_info(pkg))
                for pkg in popular_pypi[:3]:  # ìƒìœ„ 3ê°œë§Œ
                    tasks.append(self.get_pypi_package_info(pkg))
            
            # ëª¨ë“  ì‘ì—… ì‹¤í–‰
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # ê²°ê³¼ ì •ë¦¬
            result_index = 0
            
            if category in ['all', 'github']:
                summary['github_trending'].extend(results[result_index] if not isinstance(results[result_index], Exception) else [])
                result_index += 1
                summary['github_trending'].extend(results[result_index] if not isinstance(results[result_index], Exception) else [])
                result_index += 1
            
            if category in ['all', 'news']:
                tech_news = results[result_index] if not isinstance(results[result_index], Exception) else []
                summary['tech_news'] = [asdict(news) for news in tech_news[:20]]
                result_index += 1
            
            if category in ['all', 'stackoverflow']:
                summary['stackoverflow_questions'] = results[result_index] if not isinstance(results[result_index], Exception) else []
                result_index += 1
            
            if category in ['all', 'packages']:
                # NPM íŒ¨í‚¤ì§€
                for i in range(3):
                    if result_index < len(results) and not isinstance(results[result_index], Exception):
                        pkg_info = results[result_index]
                        if pkg_info:
                            summary['popular_packages']['npm'].append(asdict(pkg_info))
                    result_index += 1
                
                # PyPI íŒ¨í‚¤ì§€
                for i in range(3):
                    if result_index < len(results) and not isinstance(results[result_index], Exception):
                        pkg_info = results[result_index]
                        if pkg_info:
                            summary['popular_packages']['pypi'].append(asdict(pkg_info))
                    result_index += 1
            
            logger.info(f"ê¸°ìˆ  ì •ë³´ ìš”ì•½ ì™„ë£Œ (ì¹´í…Œê³ ë¦¬: {category})")
            return summary
            
        except Exception as e:
            logger.error(f"ê¸°ìˆ  ì •ë³´ ìš”ì•½ ì˜¤ë¥˜: {e}")
            return {'error': str(e)}

    def format_tech_summary_message(self, summary: Dict[str, Any]) -> str:
        """ê¸°ìˆ  ì •ë³´ ìš”ì•½ì„ í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ í˜•ì‹ìœ¼ë¡œ í¬ë§·"""
        try:
            message = "ğŸš€ **ìµœì‹  ê¸°ìˆ  ì •ë³´ ìš”ì•½**\n\n"
            
            # GitHub íŠ¸ë Œë”©
            if summary.get('github_trending'):
                message += "ğŸ“ˆ **GitHub íŠ¸ë Œë”©**\n"
                for repo in summary['github_trending'][:5]:
                    message += f"â­ [{repo['name']}]({repo['url']}) - {repo['stars']}â­\n"
                    if repo['description']:
                        message += f"   {repo['description'][:100]}...\n"
                message += "\n"
            
            # ê¸°ìˆ  ë‰´ìŠ¤
            if summary.get('tech_news'):
                message += "ğŸ“° **ìµœì‹  ê¸°ìˆ  ë‰´ìŠ¤**\n"
                for news in summary['tech_news'][:5]:
                    message += f"ğŸ”— [{news['title'][:50]}...]({news['url']})\n"
                    message += f"   ğŸ“… {news['source']} | ì ìˆ˜: {news['score']}\n"
                message += "\n"
            
            # Stack Overflow ì§ˆë¬¸
            if summary.get('stackoverflow_questions'):
                message += "â“ **Stack Overflow ì¸ê¸° ì§ˆë¬¸**\n"
                for q in summary['stackoverflow_questions'][:3]:
                    message += f"ğŸ¤” [{q['title'][:60]}...]({q['url']})\n"
                    message += f"   ğŸ‘ {q['score']} | ğŸ‘€ {q['view_count']} | ğŸ’¬ {q['answer_count']}\n"
                message += "\n"
            
            # ì¸ê¸° íŒ¨í‚¤ì§€
            packages = summary.get('popular_packages', {})
            if packages.get('npm') or packages.get('pypi'):
                message += "ğŸ“¦ **ì¸ê¸° íŒ¨í‚¤ì§€**\n"
                
                if packages.get('npm'):
                    message += "ğŸŸ¨ **NPM:**\n"
                    for pkg in packages['npm'][:3]:
                        message += f"   ğŸ“¦ {pkg['name']} v{pkg['version']}\n"
                
                if packages.get('pypi'):
                    message += "ğŸ **PyPI:**\n"
                    for pkg in packages['pypi'][:3]:
                        message += f"   ğŸ“¦ {pkg['name']} v{pkg['version']}\n"
            
            message += f"\nğŸ• ì—…ë°ì´íŠ¸: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
            
            return message
            
        except Exception as e:
            logger.error(f"ë©”ì‹œì§€ í¬ë§· ì˜¤ë¥˜: {e}")
            return f"âŒ ê¸°ìˆ  ì •ë³´ ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
tech_updater = TechInfoUpdater() 